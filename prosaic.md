---
permalink: /prosaic/
---
# Prosaic AI

Deep learning has achieved great successes in areas of artificial intelligence over a [relatively short period](http://realai.org/progress/). Remarkably, its main principles were established in the 1950's and 60's. Numerous technical innovations contribute to these successes, but none amounts to a profound scientific discovery such as a new theory of the mind. Many difficult cognitive tasks are solved using deep learning, surprising AI researchers who expect involvement of more explicit mathematical modeling using tools such as logic ([Darwiche, 2017](https://arxiv.org/abs/1707.04327)).

It seems increasingly plausible that high-level machine intelligence could be built by scaling up current methods in deep learning, without qualitatively new ideas about "how intelligence works" ([Christiano, 2016](https://ai-alignment.com/prosaic-ai-control-b959644d79c2)). Complex intelligent behavior can emerge from generic learning objectives when deep neural network-based models have sufficient learning capacity, and training data contains sufficient richness and diversity. Moreover, similar behavior is difficult to induce by explicit engineering in simple environments as solutions found are often idiosyncratic because they overfit the learning objectives. Under this premise, the improvement of engineering capability will lead to the creation of AGI. In a July 2017 [online report](http://www.jefftk.com/p/conversation-with-an-ai-researcher), the view from an anonymous AI researcher at one of the main industry labs is that progress in ML is "almost entirely constrained by hardware and data."

Our emphasis on Prosaic AI is about plausibility. Deep learning is only one way towards building AGI and we by no means imply that it is the only way. There are a lot of interesting discoveries that are motivated by symbolic AI, statistical machine learning, cognitive science, robotics, neuromorphic engineering, physics and other fields. Even inside machine learning, advanced systems can be built that do not use neural networks. They're promising directions but are beyond the current scope of Real AIâ€™s efforts.

## Progress

### Locomotion Behavior

In [Heess et al. (2017)](https://arxiv.org/abs/1707.02286), agents successfully learn complex locomotion behavior such as running, jumping, crouching and turning. The agents are trained with deliberately simple and generic reward functions, but over a wide range of environmental conditions. They learn faster following a curriculum. The architecture used in these agents is similar to [Heess et al. (2016)](https://arxiv.org/abs/1610.05182), an earlier work on hierarchical motor control published about 9 months before.

## Resources

* [Near-Term AI Safety](https://www.facebook.com/groups/771703926331579/) is a Facebook group in which topics related to prosaic AI are often discussed as it is one of the most plausible paths towards the creation of AGI in very near future.

## References

* 2017 July 13, Adnan Darwiche. [Human-Level Intelligence or Animal-Like Abilities?](https://arxiv.org/abs/1707.04327) *arXiv:1707.04327*. [video](https://www.youtube.com/watch?v=UTzCwCic-Do).
* 2017 July 7, Nicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel, Greg Wayne, Yuval Tassa, Tom Erez, Ziyu Wang, Ali Eslami, Martin Riedmiller, and David Silver. [Emergence of Locomotion Behaviours in Rich Environments](https://arxiv.org/abs/1707.02286). *arXiv:1707.02286*. [video](https://goo.gl/8rTx2F).
* 2016 Novenber 19, Paul Christiano. [Prosaic AI alignment](https://ai-alignment.com/prosaic-ai-control-b959644d79c2). *[AI Alignment](https://ai-alignment.com/)*.
* 2016 October 17, Nicolas Heess, Greg Wayne, Yuval Tassa, Timothy Lillicrap, Martin Riedmiller, and David Silver. [Learning and Transfer of Modulated Locomotor Controllers](https://arxiv.org/abs/1610.05182). *arXiv:1610.05182*.


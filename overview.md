---
permalink: /overview/
---
# Overview

## AI and Society

Rapid [progress](http://realai.org/progress/) in artificial intelligence (AI) has raised the prospect that machines will [one day](http://realai.org/timing/) surpass humans in intelligence. Countries around the world have [policies](http://realai.org/policies/) in place to support AI research and development, [research groups](http://realai.org/labs/) are given a lot of resources, and many experts have already published [roadmaps](http://realai.org/roadmaps/) towards building artificial general intelligence (AGI).

AGI technology could represent the greatest change in the history of life on Earth. It can bring enormous benefits to humanity, but could also spell disaster if not properly developed. Given its imminence and potential [impacts](http://realai.org/impacts/), the field deserves a lot more attention from the society.

The best place to appreciate AIâ€™s progress is at its research [frontiers](http://realai.org/review/). Unlike mature fields where many years of postgraduate training is needed, the [background](http://realai.org/resources/curriculum/) for cutting-edge AI is accessible to college students, whose papers often appear in top academic [conferences](http://realai.org/resources/conferences/).

We can take steps to ensure that it is [safe and beneficial](http://realai.org/safety/). Many things can be done today to [positively shape the development](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/) of AGI, such as research, policy, advocacy and capacity building. There are organizations around the world that could effectively use additional human and financial resources. For people who feel the urgency or are willing to contribute, there are also many opportunities, from small donations to lifetime career changes. With hard work and caution, we believe that when singularity comes, it's not going to be a disaster. It's going to be the next level of civilization. In this new world, everyone can live well and prosper.

### Near-Term Safety

In a widely cited article about [the singularity](https://en.wikipedia.org/wiki/Technological_singularity), [Vinge (1993)](http://edoras.sdsu.edu/~vinge/misc/singularity.html) predicts that greater-than-human intelligence will occur during the next 30 years. In this website, near-term safety is about keeping AGI safe and beneficial if it will be created on or before 2023. A plausible path of such a development is to scale up existing AI architectures to the level of prosaic AGI ([Christiano, 2016](https://ai-alignment.com/prosaic-ai-control-b959644d79c2)) without discovering qualitatively new ideas about how intelligence works.

## References

* 2016 November 18, Paul Christiano. [Prosaic AI alignment](https://ai-alignment.com/prosaic-ai-control-b959644d79c2). *AI Alignment*.
* 1993, Vernor Vinge. [The Coming Technological Singularity: How to Survive in the Post-Human Era](http://edoras.sdsu.edu/~vinge/misc/singularity.html). *VISION-21 Symposium*.


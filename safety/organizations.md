---
permalink: /safety/organizations/
---
# AI Safety Organizations 

Many research groups that work on AI safety are connected with [effective altruism](http://realai.org/safety/effective-altruism/) (EA).

## Machine Intelligence Research Institute

The [Machine Intelligence Research Institute](https://intelligence.org/) (MIRI) is a nonprofit that does foundational mathematical research to ensure smarter-than-human AI has a positive impact. Its [mission](https://intelligence.org/about/) is to develop formal tools with the intent of making AI systems safer and more reliable. Based on its [background claims](https://intelligence.org/2015/07/24/four-background-claims/) that  advances in AI will be among the largest determiners of human welfare, MIRI [identifies with EA](https://intelligence.org/2015/08/28/ai-and-effective-altruism/).

MIRI has a [team](https://intelligence.org/team/) of staff, advisors, research associates, and board members. All its [publications](https://intelligence.org/all-publications/) are available online. 

### History

MIRI was formerly known as the Singularity Institute (SI) for Artificial Intelligence. SI was founded in 2000 by [Eliezer S. Yudkowsky](http://yudkowsky.net/) and initially funded by Brian and Sabine Atkins to "accelerate toward AI" ([FLI, 2015](https://futureoflife.org/2015/10/11/113/)). [Luke Muehlhauser](http://lukemuehlhauser.com/) became SI's Executive Director in 2011.

Until at least 11 May 2012, it had not been a charity recommended by GiveWell Labs, presently known as the [Open Philanthropy Project](http://www.openphilanthropy.org/) (OPP). GiveWell's [Holden Karnofsky](http://www.openphilanthropy.org/about/team/holden-karnofsky) detailed his thoughts on why SI was not recommended in a [post](http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/) on Less Wrong's [discussion board](http://lesswrong.com/r/discussion/new/).

SI agreed to change name following Singularity University's [acquisition](http://singularityu.org/2012/12/09/singularity-university-acquires-the-singularity-summit/) of the Singularity Summit in December 2012, and [became](https://intelligence.org/2013/01/30/we-are-now-the-machine-intelligence-research-institute-miri/) MIRI the following January.

Luke [left](https://intelligence.org/2015/05/06/a-fond-farewell-and-a-new-executive-director/) on 6 May 2015 to accept a research postion at [GiveWell](http://realai.org/safety/effective-altruism/#givewell-good-ventures-and-the-open-philanthropy-project). [Nate Soares](http://so8r.es/) has been MIRI's Executive Director since then.

In August 2016, OPP awarded a [grant](http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/machine-intelligence-research-institute-general-support) of $500,000 to MIRI for reasons including its past positive impacts and possibly higher-than-expected future research potential. But OPP elected not to award $1.5 million per year for two years, on concerns that MIRI had made limited research progress so far and that OPP tentatively viewed MIRI's research agenda as having little potential to decrease AI risk.

In its [2017 Updates and Strategy](https://intelligence.org/2017/04/30/2017-updates-and-strategy/) published on 30 April 2017, MIRI researchers adjusted upwards their estimated probability of AGI’s being developed before 2035. Consequently, MIRI expected AGI would bear closer resemblance to present-day AI systems. It started [hiring software engineers](https://intelligence.org/2017/04/30/software-engineer-internship-staff-openings/).

## Center for Applied Rationality

[Center for Applied Rationality](http://rationality.org/) (CFAR) is a non-profit 501(c)(3) tax-exempt organization (EIN 45-3100226) in Berkeley, California. Rationality here means [“actually trying to figure things out.”](http://rationality.org/about/mission) It runs 4-day immersive workshops priced at [USD 3,900](http://rationality.org/workshops/faq#what-is-the-price-of-the-workshop) that might [not be a good fit](http://rationality.org/workshops/faq#who-shouldnt-attend-cfar-workshops) for people uncomfortable with extensive socialization. All their workshops [aim narrowly](http://rationality.org/about/mission#third-we-are-focused-specifically-on-existential-win-and-on-the-people-social-fabric-and-thinking-skills-that-might-most-help-with-that--we-see-ai-safety-as-especially-key-here) at: (a) AI safety directly; or (b) developing our rationality. [Participants below 18 years old are not allowed](http://rationality.org/workshops/faq#im-not-18-yet-can-i-still-attend) at their core workshops.

CFAR was spun off from MIRI in 2012, with which it still shares an office. Its co-founders Anna Salamon (President & Chair of Board), Julia Galef (President), Michael "Valentine" Smith (Research), and Andrew Critch (Curriculum Developer) are on the current [team](http://rationality.org/about/team) of staff, contractors, adjunct instructors, staff alumni, and board of directors.

## [Future of Humanity Institute](https://www.fhi.ox.ac.uk/):

* [Publications](http://www.fhi.ox.ac.uk/publications/)
* [Team](https://www.fhi.ox.ac.uk/about/the-team/)

## [Future of Life Institute](https://futureoflife.org/)

## [UC Berkeley Center for Human-Compatible AI](http://humancompatible.ai/)

## [Center for the Study of Existential Risk](http://cser.org/)

## Leverhulme Center for the Future of Intelligence

The [Leverhulme Center for the Future of Intelligence](http://lcfi.ac.uk/) was [launched](http://www.cam.ac.uk/research/news/the-future-of-intelligence-cambridge-university-launches-new-centre-to-study-ai-and-the-future-of) in December 2015 by the University of Cambridge, where it is also based at. It is funded by a £10 million grant from the [Leverhulme Trust](https://www.leverhulme.ac.uk/), and has a clear practical goal, "to work together to ensure that we humans make the best of the opportunities of artificial intelligence as it develops over coming decades." It runs a series of [projects](http://www.lcfi.ac.uk/projects/) on the nature and impact of AI. [Demis Hassabis](http://lcfi.ac.uk/about/people/demis-hassabis/), co-founder and CEO of DeepMind, currently sits on CFI's [international advisory board](http://lcfi.ac.uk/about/people/).

## [Foundational Research Institute](https://foundational-research.org/)

## References

* 2016 December 13, Ben Henry. [2017 AI Risk Literature Review and Charity Comparison](http://effective-altruism.com/ea/14w/2017_ai_risk_literature_review_and_charity/). *Effective Altruism Forum*.
* 2015 October 11, Future of Life Institute (FLI). [MIRI: Artificial Intelligence: The Danger of Good Intentions](https://futureoflife.org/2015/10/11/113/). *Future of Life Institute*.
